{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a RAG pipeline with Llamaindex and Meltemi."
      ],
      "metadata": {
        "id": "8xGvd3Pq1vsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting file directory and installing Llama-index modules."
      ],
      "metadata": {
        "id": "R1lwjY6n27rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FjlrCtpmusp",
        "outputId": "522dedbc-85d0-4a50-b6a9-8aa257a13ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym3uMc6f56Xv",
        "outputId": "3145d494-5f8e-454d-e21b-9e8581aa1b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf'  'Σύνταξη (γλωσσολογία) - Βικιπαίδεια.pdf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR=\"/content/drive/MyDrive/data\""
      ],
      "metadata": {
        "id": "ixh0z7GD2ml7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QkauPdp1Mwx",
        "outputId": "064d90f4-14ad-47e1-e72f-4ec58b0a4fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: llama-index-readers-file in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: llama-index-llms-litellm in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.12.2)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (5.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.0.26)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai) (1.54.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.26.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (3.2.1)\n",
            "Requirement already satisfied: litellm<2.0.0,>=1.18.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-litellm) (1.53.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (4.23.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (2.9.2)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (0.20.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (11.0.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (8.5.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (0.21.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.1.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.2->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index) (3.23.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-readers-file llama-index-llms-openai llama-index-embeddings-huggingface llama-index-llms-litellm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading required libraries"
      ],
      "metadata": {
        "id": "aiGTgXnY3Ks0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIW_WAERf3uI"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
        "from llama_index.llms.litellm import LiteLLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingesting data"
      ],
      "metadata": {
        "id": "kKGrKXdS3Rok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(DATA_DIR).load_data()\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUQWQP693ZWY",
        "outputId": "9529a1e2-e302-447c-94c6-25eaea383e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJFCAKg26m1W",
        "outputId": "2cfa0ac9-025b-4378-c02d-33db938ec2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='e36e5a4c-55ed-406d-8494-36067b48fa19', embedding=None, metadata={'page_label': '1', 'file_name': 'Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_path': '/content/drive/MyDrive/data/Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_type': 'application/pdf', 'file_size': 108823, 'creation_date': '2024-12-01', 'last_modified_date': '2024-12-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Γενετική-μετασχηματιστική γραμματική\\nΣτη γλωσσολογία, μία μετασχηματιστική γραμματική ή αλλιώς γενετική-μετασχηματιστική\\nγραμματική είναι η γενετική γραμματική, ειδικότερα μίας φυσικής γλώσσας, η οποία έχει αναπτυχθεί στις\\nσυντακτικές δομές των γραμματικών φραστικών δομών (σε αντίθεση με των γραμματικών εξάρτησης). Η\\nμετασχηματιστική γραμματική ανήκει στην παράδοση συγκεκριμένων μετασχηματιστικών γραμματικών. Η\\nέρευνα της μετασχηματιστικής γραμματικής βασίζεται κατά κύριο λόγο στο Μινιμαλιστικό Πρόγραμμα του\\nΝόαμ Τσόμσκι[1]. Ο Chomsky είναι ο εισηγητής της γενετικής-μετασχηματιστικής γραμματικής, την οποία\\nυποστήριξε κυρίως με το ριζοσπαστικό γλωσσολογικό του σύγγραμμα \"Συντακτικές Δομές\" του 1957. Η\\nγενετική θεωρία του για τη γλώσσα χαρακτηρίζεται από κάποιες σταθερές παραδοχές όπως η ικανότητα του\\nανθρώπου να παράγει και να κατανοεί άπειρο, θεωρητικά, αριθμό προτάσεων.\\xa0Ο Chomsky αναφέρει ότι\\xa0η\\nγλώσσα είναι έμφυτη και μας οδηγεί βάσιμα στην υπόθεση για την ύπαρξη γλωσσικών καθολικών,\\nγενικευμένων δομών και περιορισμών στους οποίους υπακούουν όλες οι φυσικές γλώσσες, παρά την μεγάλη\\nποικιλία τους.\\xa0Η ύπαρξη μιας εγγενούς «Καθολικής Γραμματικής» καθιστά το παιδί ικανό να μαθαίνει τη\\nμητρική του γλώσσα σε ελάχιστο χρονικό διάστημα, παρά την αποσπασματικότητα των δεδομένων τα οποία\\nπροσλαμβάνει ο άνθρωπος στα πρώτα χρόνια της ζωής του.\\nΟ Chomsky αμφισβήτησε τη συμπεριφοριστική θεωρία για τη γλωσσική κατάκτηση και προώθησε ένα\\nφορμαλιστικό πρότυπο περιγραφής και ανάλυσης της γλώσσας, κυρίως στον τομέα της σύνταξης. Ο τρόπος\\nμε τον οποίο ο Chomsky απέδωσε φορμαλιστικά τη γλωσσική ικανότητα εξηγεί επαρκώς τη λεγόμενη\\n\"γλωσσική δημιουργικότητα\", βασική ιδιότητα των φυσικών γλωσσών: με έναν πεπερασμένο αριθμό\\nκανόνων και ένα συγκεκριμένο σύνολο γλωσσικών μονάδων (φωνολογικών και λεξικών), οι άνθρωποι\\nέχουν την ικανότητα να παραγάγουν και να αντιληφθούν άπειρο πλήθος προτάσεων στις οποίες\\nσυμπεριλαμβάνονται προτάσεις που ποτέ ξανά δεν έχουν παραχθεί.\\nΣτις \"Συντακτικές Δομές\" ο Chomsky εισάγει την έννοια της \"μετασχηματιστικής γραμματικής\". Θέτει ως\\nσκοπό της γραμματικής την πρόβλεψη όλων των γραμματικών, δηλαδή σωστά σχηματισμένων, προτάσεων\\nμιας γλώσσας και μόνον αυτών. Ακόμη, πιστεύει πως, η παραγωγή προτάσεων δεν περιγράφεται\\nικανοποιητικά στο πλαίσιο γραμμικών αναπαραστάσεων: το βασίζει\\xa0στο γεγονός ότι\\xa0στις φυσικές γλώσσες\\nείναι δυνατή η απεριόριστη παρεμβολή άλλων δομών μεταξύ δύο αλληλεξαρτώμενων συστατικών, ενώ ένα\\nγραμμικό πρότυπο εξηγεί την αλληλεξάρτηση μόνο συνεχόμενων συστατικών. Έτσι, επιχειρηματολογεί\\nυπέρ της άποψης ότι η πρόταση έχει ιεραρχική δομή, η οποία μπορεί να αναπαρασταθεί στο πλαίσιο των\\nγραμματικών φραστικής δομής. Οι κανόνες φραστικής δομής προσφέρουν το πλεονέκτημα της\\n\"αναδρομής\", δηλαδή, της ιδιότητας των κανόνων να μπορούν να εφαρμόζονται απεριόριστα.\\nΣυμπερασματικά, οι βασικές απόψεις του Chomsky είναι οι εξής:\\n-Η γλωσσική δημιουργικότητα του ανθρώπου είναι γενετικά καθορισμένη, άρα καθολική (έτσι, ανατρέπεται\\nτο συμπεριφορικό πρότυπο)\\n-Τα βασικά χαρακτηριστικά της γλώσσας προϋπάρχουν ως εγγενή στοιχεία (δομές) στο μυαλό του παιδιού\\nκαι ενεργοποιούνται στο γλωσσικό περιβάλλον όπου μεγαλώνει\\n12/1/24, 6:30 PM Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια\\nhttps://el.wikipedia.org/wiki/Γενετική-μετασχηματιστική_γραμματική 1/2', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking documents"
      ],
      "metadata": {
        "id": "HDwD-cVP3sB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkxtcViPem_3"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
        "\n",
        "splitter = SemanticSplitterNodeParser(\n",
        "    buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model\n",
        ")\n",
        "\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoRp6VABF1mr",
        "outputId": "0d6a5bd0-947c-4255-e04f-6028c9e15f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARvimQbr7R9W",
        "outputId": "38e8503d-b3c8-4154-d69e-eeafebc8aaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextNode(id_='eeb9cf13-63d8-42a8-ae0b-718ed876ae85', embedding=None, metadata={'page_label': '1', 'file_name': 'Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_path': '/content/drive/MyDrive/data/Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_type': 'application/pdf', 'file_size': 108823, 'creation_date': '2024-12-01', 'last_modified_date': '2024-12-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e36e5a4c-55ed-406d-8494-36067b48fa19', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_path': '/content/drive/MyDrive/data/Γενετική-μετασχηματιστική γραμματική - Βικιπαίδεια.pdf', 'file_type': 'application/pdf', 'file_size': 108823, 'creation_date': '2024-12-01', 'last_modified_date': '2024-12-01'}, hash='cb53e5b2a3cd8f2d2fe5f753b62771a08138a617b5fab2e9d69ff6081fb6efc1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c02bd6f8-4dea-4c4a-9907-c718c1b1849e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='40b4f4a38ba1e1ffe2c70c29793de4c8b6f7a9a7db9539da3d02748fac79f7b7')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Γενετική-μετασχηματιστική γραμματική\\nΣτη γλωσσολογία, μία μετασχηματιστική γραμματική ή αλλιώς γενετική-μετασχηματιστική\\nγραμματική είναι η γενετική γραμματική, ειδικότερα μίας φυσικής γλώσσας, η οποία έχει αναπτυχθεί στις\\nσυντακτικές δομές των γραμματικών φραστικών δομών (σε αντίθεση με των γραμματικών εξάρτησης). Η\\nμετασχηματιστική γραμματική ανήκει στην παράδοση συγκεκριμένων μετασχηματιστικών γραμματικών. Η\\nέρευνα της μετασχηματιστικής γραμματικής βασίζεται κατά κύριο λόγο στο Μινιμαλιστικό Πρόγραμμα του\\nΝόαμ Τσόμσκι[1]. Ο Chomsky είναι ο εισηγητής της γενετικής-μετασχηματιστικής γραμματικής, την οποία\\nυποστήριξε κυρίως με το ριζοσπαστικό γλωσσολογικό του σύγγραμμα \"Συντακτικές Δομές\" του 1957. Η\\nγενετική θεωρία του για τη γλώσσα χαρακτηρίζεται από κάποιες σταθερές παραδοχές όπως η ικανότητα του\\nανθρώπου να παράγει και να κατανοεί άπειρο, θεωρητικά, αριθμό προτάσεων.\\xa0Ο Chomsky αναφέρει ότι\\xa0η\\nγλώσσα είναι έμφυτη και μας οδηγεί βάσιμα στην υπόθεση για την ύπαρξη γλωσσικών καθολικών,\\nγενικευμένων δομών και περιορισμών στους οποίους υπακούουν όλες οι φυσικές γλώσσες, παρά την μεγάλη\\nποικιλία τους.\\xa0Η ύπαρξη μιας εγγενούς «Καθολικής Γραμματικής» καθιστά το παιδί ικανό να μαθαίνει τη\\nμητρική του γλώσσα σε ελάχιστο χρονικό διάστημα, παρά την αποσπασματικότητα των δεδομένων τα οποία\\nπροσλαμβάνει ο άνθρωπος στα πρώτα χρόνια της ζωής του.\\nΟ Chomsky αμφισβήτησε τη συμπεριφοριστική θεωρία για τη γλωσσική κατάκτηση και προώθησε ένα\\nφορμαλιστικό πρότυπο περιγραφής και ανάλυσης της γλώσσας, κυρίως στον τομέα της σύνταξης. Ο τρόπος\\nμε τον οποίο ο Chomsky απέδωσε φορμαλιστικά τη γλωσσική ικανότητα εξηγεί επαρκώς τη λεγόμενη\\n\"γλωσσική δημιουργικότητα\", βασική ιδιότητα των φυσικών γλωσσών: με έναν πεπερασμένο αριθμό\\nκανόνων και ένα συγκεκριμένο σύνολο γλωσσικών μονάδων (φωνολογικών και λεξικών), οι άνθρωποι\\nέχουν την ικανότητα να παραγάγουν και να αντιληφθούν άπειρο πλήθος προτάσεων στις οποίες\\nσυμπεριλαμβάνονται προτάσεις που ποτέ ξανά δεν έχουν παραχθεί.\\nΣτις \"Συντακτικές Δομές\" ο Chomsky εισάγει την έννοια της \"μετασχηματιστικής γραμματικής\". Θέτει ως\\nσκοπό της γραμματικής την πρόβλεψη όλων των γραμματικών, δηλαδή σωστά σχηματισμένων, προτάσεων\\nμιας γλώσσας και μόνον αυτών. Ακόμη, πιστεύει πως, η παραγωγή προτάσεων δεν περιγράφεται\\nικανοποιητικά στο πλαίσιο γραμμικών αναπαραστάσεων: το βασίζει\\xa0στο γεγονός ότι\\xa0στις φυσικές γλώσσες\\nείναι δυνατή η απεριόριστη παρεμβολή άλλων δομών μεταξύ δύο αλληλεξαρτώμενων συστατικών, ενώ ένα\\nγραμμικό πρότυπο εξηγεί την αλληλεξάρτηση μόνο συνεχόμενων συστατικών. Έτσι, επιχειρηματολογεί\\nυπέρ της άποψης ότι η πρόταση έχει ιεραρχική δομή, η οποία μπορεί να αναπαρασταθεί στο πλαίσιο των\\nγραμματικών φραστικής δομής. ', mimetype='text/plain', start_char_idx=0, end_char_idx=2679, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_nIieTBiEML"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
        "index = VectorStoreIndex(nodes, embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbK4SmERmZNy"
      },
      "outputs": [],
      "source": [
        "# gpt35 = LLamaIndexOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
        "# meltemi = LLamaIndexOpenAI(api_key=MELTEMI_API_KEY, base_url=MELTEMI_BASE_URL, model=\"meltemi-instruct-7b\")\n",
        "\n",
        "meltemi = LiteLLM(\n",
        "    \"hosted_vllm/meltemi-vllm\",\n",
        "    api_base=\"http://ec2-3-19-37-251.us-east-2.compute.amazonaws.com:4000/\",\n",
        "    api_key=\"sk-RYF0g_hDDIa2TLiHFboZ1Q\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGi6OgNUVDcg"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.prompts import (\n",
        "    SelectorPromptTemplate,\n",
        "    PromptType,\n",
        "    PromptTemplate,\n",
        "    MessageRole,\n",
        "    ChatPromptTemplate,\n",
        "    ChatMessage,\n",
        ")\n",
        "\n",
        "QA_PROMPT = \"\"\"BEGININPUT\n",
        "{context_str}\n",
        "\n",
        "ENDINPUT\n",
        "BEGININSTRUCTION\n",
        "{query_str}\n",
        "ENDINSTRUCTION\"\"\"\n",
        "\n",
        "QA_SYSTEM_PROMPT = \"\"\"Είσαι ένας ειλικρινής και αμερόληπτος βοηθός που πάντα απαντάει με ακρίβεια σε αυτά που του ζητούνται.\n",
        "Σου δίνονται δύο έγγραφα τα οποία βρίσκονται μεταξύ του BEGININPUT και του ENDINPUT.\n",
        "Επίσης, σου δίνονται μεταδεδομένα για τα συγκεκριμένα έγγραφα μεταξύ του BEGINCONTEXT και του ENDCONTEXT.\n",
        "Το βασικό κείμενο των εγγράφων βρίσκεται μεταξύ του ENDCONTEXT και του ENDINPUT.\n",
        "Απάντησε στις οδηγίες του χρήστη που βρίσκονται μεταξύ του BEGININSTRUCTION και του ENDINSTRUCTION χρησιμοποιώντας μόνο το βασικό κείμενο\n",
        "και τα μεταδεδομένα των εγγράφων που σου δίνονται παρακάτω. Αν οι οδηγίες που σου ζητάει ο χρήστης δεν μπορούν να απαντηθούν με το βασικό\n",
        "κείμενο ή τα μεταδεδομένα των εγγράφων, ενημέρωσε τον χρήστη ότι δεν ξέρεις τη σωστή απάντηση.\"\"\"\n",
        "\n",
        "REFINE_PROMPT = \"\"\"Η αρχική ερώτηση είναι η εξής: {query_str}\n",
        "Έχεις δώσει την παρακάτω απάντηση: {existing_answer}\n",
        "Έχεις την ευκαιρία να βελτιώσεις την προηγούμενη απάντηση (μόνο αν χρειάζεται) με τις παρακάτω νέες πληροφορίες.\n",
        "------------\n",
        "{context_str}\n",
        "------------\n",
        "Με βάση τις νέες πληροφορίες, βελτίωσε την απάντησή σου για να απαντά καλύτερα στην ερώτηση.\n",
        "Αν οι πληροφορίες δεν είναι χρήσιμες, απλά επανάλαβε την προηγούμενη απάντηση.\n",
        "Βελτιωμένη απάντηση: \"\"\"\n",
        "\n",
        "REFINE_CHAT_PROMPT = \"\"\"Είσαι ένα έμπιστο σύστημα που απαντάει ερωτήσεις χρηστών. Λειτουργείς με τους εξής δύο τρόπους όταν βελτιώνεις υπάρχουσες απαντήσεις:\n",
        "1. **Ξαναγράφεις** την απάντηση με βάση νέες πληροφορίες που σου παρέχονται\n",
        "2. **Επαναλαμβάνεις** την προηγούμενη απάντηση αν δεν είναι χρήσιμες οι νέες πληροφορίες\n",
        "\n",
        "Ποτέ δεν αναφέρεις την αρχική απάντηση ή το συγκείμενο απευθείας στην απάντησή σου.\n",
        "Αν υπάρχει αμφιβολία για το τι πρέπει να απαντήσεις, απλά επανέλαβε την αρχική απάντηση.\n",
        "Νέες πληροφορίες:\n",
        "------------\n",
        "{context_str}\n",
        "------------\n",
        "Ερώτηση: {query_str}\n",
        "Αρχική απάντηση: {existing_answer}\n",
        "Βελτιωμένη απάντηση: \"\"\"\n",
        "\n",
        "\n",
        "default_template = PromptTemplate(\n",
        "    metadata={\"prompt_type\": PromptType.QUESTION_ANSWER},\n",
        "    # template_vars=[\"context_str\", \"query_str\"],\n",
        "    template=QA_PROMPT,\n",
        ")\n",
        "chat_template = ChatPromptTemplate(\n",
        "    metadata={\"prompt_type\": PromptType.CUSTOM},\n",
        "    # template_vars=[\"context_str\", \"query_str\"],\n",
        "    message_templates=[\n",
        "        ChatMessage(role=MessageRole.SYSTEM, content=QA_SYSTEM_PROMPT),\n",
        "        ChatMessage(role=MessageRole.USER, content=QA_PROMPT),\n",
        "    ],\n",
        ")\n",
        "text_qa_prompt = SelectorPromptTemplate(\n",
        "    default_template=default_template, conditionals=[(lambda llm: True, chat_template)]\n",
        ")\n",
        "\n",
        "default_refine_template = PromptTemplate(\n",
        "    metadata={\"prompt_type\": PromptType.REFINE},\n",
        "    # template_vars=[\"query_str\", \"existing_answer\", \"context_str\"],\n",
        "    template=REFINE_PROMPT,\n",
        ")\n",
        "chat_refine_template = ChatPromptTemplate(\n",
        "    metadata={\"prompt_type\": PromptType.CUSTOM},\n",
        "    # template_vars=[\"context_str\", \"query_str\", \"existing_answer\"],\n",
        "    message_templates=[ChatMessage(role=MessageRole.USER, content=REFINE_CHAT_PROMPT)],\n",
        ")\n",
        "text_refine_prompt = SelectorPromptTemplate(\n",
        "    default_template=default_refine_template,\n",
        "    conditionals=[(lambda llm: True, chat_refine_template)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    llm=meltemi, text_qa_prompt=text_qa_prompt, text_refine_prompt=text_refine_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "WEkeh7UCBZO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Ποιος είναι ο στόχος του γλωσσολόγου σύμφωνα με την γενετική μετασχηματιστική γραμματική;\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC1vxKDSBsTV",
        "outputId": "3e889166-8830-4c71-b0b5-a4d8ba869593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ο στόχος του γλωσσολόγου σύμφωνα με την γενετική μετασχηματιστική γραμματική είναι να συλλάβει και να περιγράψει τον μηχανισμό γένεσης των προτάσεων, συγκεκριμένα τη γλωσσική ικανότητα, η οποία περιλαμβάνει την περιγραφή της γλωσσικής επιτέλεσης, δηλαδή της ικανότητας παραγωγής λόγου σε πραγματικές περιστάσεις όπου μεσολαβούν διάφοροι ψυχολογικοί παράγοντες.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Πώς αιτιολογείται η ύπαρξη της καθολικής γραμματικής σύμφωνα με τον Noam Chomsky;\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "xUQkHOTQC-Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced01d4c-3a47-4231-f787-5421e3908f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Η ύπαρξη της καθολική γραμματικής σύμφωνα με τον Noam Chomsky αιτιολογείται από την άποψη ότι η πρόταση έχει ιεραρχική δομή, η οποία μπορεί να αναπαρασταθεί στο πλαίσιο των γραμματικών φραστικής δομής. Οι κανόνες φραστικής δομής προσφέρουν το πλεονέκτημα της \"αναδρομής\", δηλαδή, της ιδιότητας των κανόνων να μπορούν να εφαρμόζονται απεριόριστα. Επιπλέον, η γενετική-μετασχηματιστική γραμματική, η οποία προτάθηκε από τον Chomsky, υποστηρίζει ότι η γλώσσα προϋπάρχουν ως εγγενή στοιχεία (δομές) στο μυαλό του παιδιού και ενεργοποιούνται στο γλωσσικό περιβάλλον όπου μεγαλώνει.\n"
          ]
        }
      ]
    }
  ]
}